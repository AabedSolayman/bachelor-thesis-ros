
@misc{przybyla_obstacle_detector_2020,
	title = {Obstacle\_detector},
	url = {https://github.com/tysik/obstacle_detector},
	abstract = {A ROS package for 2D obstacle detection based on laser range data.},
	urldate = {2020-05-21},
	author = {Przybyla, Mateusz},
	month = may,
	year = {2020},
	note = {https://github.com/tysik/obstacle\_detector, Accessed Date: 22.05.2020}
}

@misc{noauthor_laser_nodate,
	title = {Laser {Filters} - {ROS} {Wiki}},
	url = {http://wiki.ros.org/laser_filters},
	urldate = {2020-04-21},
	note = {http://wiki.ros.org/laser\_filters, Accessed Date: 21.04.2020},
	file = {laser_filters - ROS Wiki:/home/legoboost/Zotero/storage/G77PLBGF/laser_filters.html:text/html}
}

@misc{conley_nodes_nodate,
	title = {Nodes - {ROS} {Wiki}},
	url = {http://wiki.ros.org/Nodes},
	urldate = {2020-05-22},
	author = {Conley, Ken},
	note = {http://wiki.ros.org/Nodes, Accessed Date: 22.05.2020},
	file = {Nodes - ROS Wiki:/home/legoboost/Zotero/storage/MGY6BT6M/Nodes.html:text/html}
}

@book{joseph_learning_2018,
	title = {Learning {Robotics} using {Python} - {Second} {Edition}},
	isbn = {978-1-78862-331-5},
	url = {https://subscription.packtpub.com/book/hardware_and_creative/9781788623315/1/ch01lvl1sec11/introduction-to-ros},
	abstract = {ROS is a software framework used for creating robotic applications.},
	language = {en},
	urldate = {2020-05-22},
	author = {Joseph, Lentin},
	month = jun,
	year = {2018},
	file = {Snapshot:/home/legoboost/Zotero/storage/LXHSMX8L/introduction-to-ros.html:text/html}
}

@misc{noauthor_mecabrickscom_nodate,
	title = {Mecabricks.com},
	url = {https://www.mecabricks.com/en/},
	urldate = {2020-05-22},
	note = {https://www.mecabricks.com/en/, Accessed Date: 23.05.2020},
	file = {Mecabricks.com:/home/legoboost/Zotero/storage/RK7FWDXV/en.html:text/html}
}

@misc{noauthor_coordinate_nodate,
	title = {Coordinate {Frames} for {Humanoid} {Robots}},
	url = {https://www.ros.org/reps/rep-0120.html#base-footprint},
	urldate = {2020-05-23},
	note = {https://www.ros.org/reps/rep-0120.html\#base-footprint, Date Accessed: 23.05.2020},
	file = {REP 120 -- Coordinate Frames for Humanoid Robots (ROS.org):/home/legoboost/Zotero/storage/WSGD3F65/rep-0120.html:text/html}
}

@misc{noauthor_urdf_nodate,
	title = {{URDF} {Joint} - {ROS} {Wiki}},
	url = {http://wiki.ros.org/urdf/XML/joint},
	urldate = {2020-05-23},
	note = {http://wiki.ros.org/urdf/XML/joint, Accessed Date: 23.05.2020},
	file = {urdf/XML/joint - ROS Wiki:/home/legoboost/Zotero/storage/BKC2TRN6/joint.html:text/html}
}

@inproceedings{przybyla_detection_2017,
	title = {Detection and tracking of {2D} geometric obstacles from {LRF} data},
	doi = {10.1109/RoMoCo.2017.8003904},
	abstract = {This work proposes a method for detection and tracking of local geometrical obstacles from sequences of two-dimensional range scans. Detected obstacles are represented with linear or circular models. Circular obstacles are subject to tracking algorithm based on Kalman filter. Solutions to both the correspondence and the update problem of the tracking system are provided. The occurence of obstacles fusion or fission is defined and addressed. A by-product of the system is the information on tracked obstacles velocity. The algorithm is dedicated to wheeled mobile robots with mounted planar laser range finders.},
	booktitle = {2017 11th {International} {Workshop} on {Robot} {Motion} and {Control} ({RoMoCo})},
	author = {Przybyla, Mateusz},
	month = jul,
	year = {2017},
	keywords = {2D geometric obstacle detection, 2D geometric obstacle tracking, Collision avoidance, Computational modeling, Geometry, image filtering, Kalman filter, Kalman filters, laser ranging, LRF data, mobile robots, Mobile robots, mounted planar laser range finders, object detection, object tracking, obstacles fission, obstacles fusion, optical tracking, Robot sensing systems, tracked obstacles velocity, tracking algorithm, Two dimensional displays, wheeled mobile robots},
	pages = {135--141},
	file = {IEEE Xplore Abstract Record:/home/legoboost/Zotero/storage/66PGI5K2/8003904.html:text/html}
}

@misc{noauthor_sensor_msgs_nodate,
	title = {sensor\_msgs - {LaserScan} {Documentation}},
	url = {http://docs.ros.org/melodic/api/sensor_msgs/html/msg/LaserScan.html},
	urldate = {2020-05-26},
	note = {http://docs.ros.org/melodic/api/sensor\_msgs/
html/msg/LaserScan.html, Accessed Date: 26.05.2020},
	file = {sensor_msgs/LaserScan Documentation:/home/legoboost/Zotero/storage/5RUDKG59/LaserScan.html:text/html}
}

@misc{noauthor_sensor_msgs_nodate-1,
	title = {sensor\_msgs - {ROS} {Wiki}},
	url = {https://wiki.ros.org/sensor_msgs},
	urldate = {2020-05-26},
	file = {sensor_msgs - ROS Wiki:/home/legoboost/Zotero/storage/BUYGPPVS/sensor_msgs.html:text/html}
}

@book{yoonseok_ros_2017,
	title = {{ROS} {Robot} {Programming} ({English})},
	isbn = {979-11-962307-1-5},
	url = {http://community.robotsource.org/t/download-the-ros-robot-programming-book-for-free/51},
	publisher = {ROBOTIS},
	author = {Yoonseok, Pyo and Darby, Lim and Hancheol, Cho and Leon, Jung},
	year = {2017}
}

@misc{noauthor_opencv_nodate,
	title = {{OpenCV}: {Introduction} to {OpenCV}-{Python} {Tutorials}},
	url = {https://docs.opencv.org/master/d0/de3/tutorial_py_intro.html},
	urldate = {2020-06-07},
	note = {https://docs.opencv.org/master/d0/de3/tutorial\_py\_intro.html, Date Accessed: 07.06.2020},
	file = {OpenCV\: Introduction to OpenCV-Python Tutorials:/home/legoboost/Zotero/storage/3IQ4965Q/tutorial_py_intro.html:text/html}
}

@inproceedings{censi_accurate_2007,
	address = {Rome, Italy},
	title = {An accurate closed-form estimate of {ICP}'s covariance},
	isbn = {978-1-4244-0602-9 978-1-4244-0601-2},
	url = {http://ieeexplore.ieee.org/document/4209579/},
	doi = {10.1109/ROBOT.2007.363961},
	abstract = {Existing methods for estimating the covariance of the ICP (Iterative Closest/Corresponding Point) algorithm are either inaccurate or are computationally too expensive to be used online. This paper proposes a new method, based on the analysis of the error function being minimized. It considers that the correspondences are not independent (the same measurement being used in more than one correspondence), and explicitly utilizes the covariance matrix of the measurements, which are not assumed to be independent either. The validity of the approach is veriﬁed through extensive simulations: it is more accurate than previous methods and its computational load is negligible. The ill-posedness of the surface matching problem is explicitly tackled for under-constrained situations by performing an observability analysis; in the analyzed cases the method still provides a good estimate of the error projected on the observable manifold.},
	language = {en},
	urldate = {2020-06-17},
	booktitle = {Proceedings 2007 {IEEE} {International} {Conference} on {Robotics} and {Automation}},
	publisher = {IEEE},
	author = {Censi, Andrea},
	month = apr,
	year = {2007},
	note = {ISSN: 1050-4729},
	pages = {3167--3172},
	file = {Censi - 2007 - An accurate closed-form estimate of ICP's covarian.pdf:/home/legoboost/Zotero/storage/Q3ACBGBM/Censi - 2007 - An accurate closed-form estimate of ICP's covarian.pdf:application/pdf}
}

@misc{censi_csm_nodate,
	title = {{CSM} {\textbar} {Andrea} {Censi}'s {Website}},
	url = {https://censi.science/software/csm/},
	language = {en-US},
	urldate = {2020-06-17},
	author = {Censi, Andrea},
	note = {https://censi.science/software/csm/, Accessed Date: 17.06.2020},
	file = {Snapshot:/home/legoboost/Zotero/storage/LLLRS98R/csm.html:text/html}
}

@misc{noauthor_laser_nodate-1,
	title = {Laser {Scan} {Matcher} - {ROS} {Wiki}},
	url = {http://wiki.ros.org/laser_scan_matcher},
	urldate = {2020-06-17},
	note = {http://wiki.ros.org/laser\_scan\_matcher, Date Accessed: 17.06.2020},
	file = {laser_scan_matcher - ROS Wiki:/home/legoboost/Zotero/storage/5ELCK3WB/laser_scan_matcher.html:text/html}
}

@misc{noauthor_catkin_nodate,
	title = {Catkin {Conceptional} {Overview} - {ROS} {Wiki}},
	url = {http://wiki.ros.org/catkin/conceptual_overview},
	urldate = {2020-06-18},
	note = {http://wiki.ros.org/catkin/conceptual\_overview, Accesed Date: 18.06.2020},
	file = {catkin/conceptual_overview - ROS Wiki:/home/legoboost/Zotero/storage/EMINHICW/conceptual_overview.html:text/html}
}

@book{calis_roboter_2020,
	title = {Roboter mit {ROS}: {Bots} konstruieren und mit {Open} {Source} programmieren},
	isbn = {978-3-96088-468-2},
	shorttitle = {Roboter mit {ROS}},
	abstract = {Bauen Sie Ihren Roboter - mit professionellen Tools   Robotik praktisch erklärt Robot Operating System (ROS) kennen lernen und für eigene Prototypen einsetzen Simulation, Konstruktion und Programmierung zwei Roboter-Selbstbauprojekte für Bots mit fortgeschrittenen Fähigkeiten Mit diesem Buch erweitern Sie Ihr Verständnis für Robotik, können Entwicklungsschritte von der Simulation bis zur Programmierung selbst ausprobieren und lernen, außergewöhnliche Bots für eigene Anwendungszwecke zu konstruieren. Für die Steuerung führt Sie Murat Calis in das Robot Operating System (ROS) ein. Dieses Buch präsentiert die Möglichkeiten der Software auf verständliche Weise. So wird das Steuerungs-Framework nach kurzer Einarbeitung immer einfacher zu verstehen und zu bedienen. Murat Calis bietet in diesem Buch eine detaillierte Anleitung zur Erstellung eines virtuellen Prototyps und zeigt anschließend die Simulations- und Programmiermöglichkeiten mit ROS. Zwei Robotermodelle, die nachgebaut werden können, zeigen beispielhaft den Arbeitsfluss von der Idee zum Prototyp. Behandelt werden folgende Themen:   Simulationen mit Gazebo Kartografierung und Kinematik mit RViz Autonome kollisionsfreie Navigation mit SLAM Gesichtserkennung mit OpenCV Sie lernen anhand der im Buch vorgestellten Robotermodelle das Publish-/Subscribe-Prinzip von ROS kennen. Nachdem Sie das Zusammenspiel unabhängiger Software-Module innerhalb eines Roboters verstanden haben, geht es spielerisch weiter, indem Sie die Roboter in einer Simulation starten oder eine virtuelle Welt kartografieren lassen. Die kommentierten Programmierbeispiele setzen Sie in die Lage, eigene Programme zu schreiben.},
	language = {de},
	publisher = {dpunkt.verlag},
	author = {Calis, Murat},
	month = jan,
	year = {2020},
	keywords = {Technology \& Engineering / Robotics}
}

@book{tzafestas_introduction_2013,
	title = {Introduction to {Mobile} {Robot} {Control}},
	isbn = {978-0-12-417103-9},
	abstract = {Introduction to Mobile Robot Control provides a complete and concise study of modeling, control, and navigation methods for wheeled non-holonomic and omnidirectional mobile robots and manipulators. The book begins with a study of mobile robot drives and corresponding kinematic and dynamic models, and discusses the sensors used in mobile robotics. It then examines a variety of model-based, model-free, and vision-based controllers with unified proof of their stabilization and tracking performance, also addressing the problems of path, motion, and task planning, along with localization and mapping topics. The book provides a host of experimental results, a conceptual overview of systemic and software mobile robot control architectures, and a tour of the use of wheeled mobile robots and manipulators in industry and society. Introduction to Mobile Robot Control is an essential reference, and is also a textbook suitable as a supplement for many university robotics courses. It is accessible to all and can be used as a reference for professionals and researchers in the mobile robotics field. Clearly and authoritatively presents mobile robot conceptsRichly illustrated throughout with figures and examplesKey concepts demonstrated with a host of experimental and simulation examplesNo prior knowledge of the subject is required; each chapter commences with an introduction and background},
	language = {en},
	publisher = {Elsevier},
	author = {Tzafestas, Spyros G.},
	month = oct,
	year = {2013},
	keywords = {Technology \& Engineering / Robotics, Computers / Intelligence (AI) \& Semantics}
}

@article{rubio_review_2019,
	title = {A review of mobile robots: {Concepts}, methods, theoretical framework, and applications},
	issn = {1729-8814},
	shorttitle = {A review of mobile robots},
	url = {https://doi.org/10.1177/1729881419839596},
	doi = {10.1177/1729881419839596},
	abstract = {Humanoid robots, unmanned rovers, entertainment pets, drones, and so on are great examples of mobile robots. They can be distinguished from other robots by their ability to move autonomously, with enough intelligence to react and make decisions based on the perception they receive from the environment. Mobile robots must have some source of input data, some way of decoding that input, and a way of taking actions (including its own motion) to respond to a changing world. The need to sense and adapt to an unknown environment requires a powerful cognition system. Nowadays, there are mobile robots that can walk, run, jump, and so on like their biological counterparts. Several fields of robotics have arisen, such as wheeled mobile robots, legged robots, flying robots, robot vision, artificial intelligence, and so on, which involve different technological areas such as mechanics, electronics, and computer science. In this article, the world of mobile robots is explored including the new trends. These new trends are led by artificial intelligence, autonomous driving, network communication, cooperative work, nanorobotics, friendly human–robot interfaces, safe human–robot interaction, and emotion expression and perception. Furthermore, these news trends are applied to different fields such as medicine, health care, sports, ergonomics, industry, distribution of goods, and service robotics. These tendencies will keep going their evolution in the coming years.},
	language = {en},
	urldate = {2020-06-21},
	journal = {International Journal of Advanced Robotic Systems},
	author = {Rubio, Francisco and Valero, Francisco and Llopis-Albert, Carlos},
	month = mar,
	year = {2019},
	file = {SAGE PDF Full Text:/home/legoboost/Zotero/storage/V4ULMJW9/Rubio et al. - 2019 - A review of mobile robots Concepts, methods, theo.pdf:application/pdf}
}

@book{corke_robotics_2017,
	title = {Robotics, {Vision} and {Control}: {Fundamental} {Algorithms} {In} {MATLAB}® {Second}, {Completely} {Revised}, {Extended} {And} {Updated} {Edition}},
	isbn = {978-3-319-54413-7},
	shorttitle = {Robotics, {Vision} and {Control}},
	abstract = {Robotic vision, the combination of robotics and computer vision, involves the application of computer algorithms to data acquired from sensors. The research community has developed a large body of such algorithms but for a newcomer to the field this can be quite daunting. For over 20 years the author has maintained two open-source MATLAB® Toolboxes, one for robotics and one for vision. They provide implementations of many important algorithms and allow users to work with real problems, not just trivial examples. This book makes the fundamental algorithms of robotics, vision and control accessible to all. It weaves together theory, algorithms and examples in a narrative that covers robotics and computer vision separately and together. Using the latest versions of the Toolboxes the author shows how complex problems can be decomposed and solved using just a few simple lines of code. The topics covered are guided by real problems observed by the author over many years as a practitioner of both robotics and computer vision. It is written in an accessible but informative style, easy to read and absorb, and includes over 1000 MATLAB and Simulink® examples and over 400 figures. The book is a real walk through the fundamentals of mobile robots, arm robots. then camera models, image processing, feature extraction and multi-view geometry and finally bringing it all together with an extensive discussion of visual servo systems. This second edition is completely revised, updated and extended with coverage of Lie groups, matrix exponentials and twists; inertial navigation; differential drive robots; lattice planners; pose-graph SLAM and map making; restructured material on arm-robot kinematics and dynamics; series-elastic actuators and operational-space control; Lab color spaces; light field cameras; structured light, bundle adjustment and visual odometry; and photometric visual servoing. “An authoritative book, reaching across fields, thoughtfully conceived and brilliantly accomplished!” OUSSAMA KHATIB, Stanford},
	language = {en},
	publisher = {Springer},
	author = {Corke, Peter},
	month = may,
	year = {2017},
	keywords = {Technology \& Engineering / Robotics, Computers / Intelligence (AI) \& Semantics, Computers / Computer Graphics, Computers / Optical Data Processing, Psychology / Cognitive Psychology \& Cognition, Technology \& Engineering / Automation, Technology \& Engineering / Electronics / General, Technology \& Engineering / Imaging Systems, Technology \& Engineering / Manufacturing}
}

@article{aqel_review_2016,
	title = {Review of visual odometry: types, approaches, challenges, and applications},
	volume = {5},
	issn = {2193-1801},
	shorttitle = {Review of visual odometry},
	url = {https://doi.org/10.1186/s40064-016-3573-7},
	doi = {10.1186/s40064-016-3573-7},
	abstract = {Accurate localization of a vehicle is a fundamental challenge and one of the most important tasks of mobile robots. For autonomous navigation, motion tracking, and obstacle detection and avoidance, a robot must maintain knowledge of its position over time. Vision-based odometry is a robust technique utilized for this purpose. It allows a vehicle to localize itself robustly by using only a stream of images captured by a camera attached to the vehicle. This paper presents a review of state-of-the-art visual odometry (VO) and its types, approaches, applications, and challenges. VO is compared with the most common localization sensors and techniques, such as inertial navigation systems, global positioning systems, and laser sensors. Several areas for future research are also highlighted.},
	number = {1},
	urldate = {2020-07-31},
	journal = {SpringerPlus},
	author = {Aqel, Mohammad O. A. and Marhaban, Mohammad H. and Saripan, M. Iqbal and Ismail, Napsiah Bt.},
	month = oct,
	year = {2016},
	pages = {1897},
	file = {Snapshot:/home/legoboost/Zotero/storage/P8C94BP5/s40064-016-3573-7.html:text/html;Full Text:/home/legoboost/Zotero/storage/S5RP4AGM/Aqel et al. - 2016 - Review of visual odometry types, approaches, chal.pdf:application/pdf}
}

@misc{industries_adafruit_nodate,
	title = {Adafruit {Ultimate} {GPS} with {USB}},
	url = {https://www.adafruit.com/product/4279},
	abstract = {The Ultimate GPS module you know and love has a glow-up to let it be easily used with any computer, not just microcontrollers! With the built in USB-to-Serial converter, you can now  ...},
	urldate = {2020-07-31},
	author = {Industries, Adafruit},
	note = {https://www.adafruit.com/product/4279, Accessed Date: 31.07.2020},
	file = {Snapshot:/home/legoboost/Zotero/storage/7X54WEQ2/4279.html:text/html}
}

@misc{noauthor_sparkfun_nodate,
	title = {{SparkFun} {GPS}-{RTK2} {Board} - {SparkFun} {Electronics}},
	url = {https://www.sparkfun.com/products/15136},
	urldate = {2020-07-31},
	note = {https://www.sparkfun.com/products/15136, Accessed Date: 31.07.2020},
	file = {SparkFun GPS-RTK2 Board - ZED-F9P (Qwiic) - GPS-15136 - SparkFun Electronics:/home/legoboost/Zotero/storage/NBWE8X54/15136.html:text/html}
}

@misc{kwillms_english_2012,
	title = {English: {Triangulation}},
	shorttitle = {English},
	url = {https://commons.wikimedia.org/wiki/File:Triangulation_englisch.jpg},
	urldate = {2020-08-01},
	author = {{K.Willms}},
	month = nov,
	year = {2012},
	note = {https://commons.wikimedia.org/wiki/File:Triangulation\_englisch.jpg, Date Accessed: 01.08.2020},
	file = {Wikimedia Snapshot:/home/legoboost/Zotero/storage/8JEB5S2I/FileTriangulation_englisch.html:text/html}
}
